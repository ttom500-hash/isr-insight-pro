import streamlit as st
import google.generativeai as genai
import google.api_core.exceptions
import tempfile
import os
import time

# --- 1. ×”×’×“×¨×ª ×“×£ ---
st.set_page_config(page_title="Apex Pro Enterprise", page_icon="ğŸ¢", layout="wide")

# --- 2. ×¢×™×¦×•×‘ RTL ---
st.markdown("""<style>.stApp {direction: rtl;} h1, h2, h3, p, div {text-align: right;} 
.stTextInput>div>div>input {text-align: right;} .stSelectbox>div>div>div {text-align: right;} 
.stChatMessage {direction: rtl; text-align: right;} .stDeployButton {display:none;}</style>""", unsafe_allow_html=True)

st.title("ğŸ¢ Apex Pro - ××¢×¨×›×ª ×—×¡×™× ×ª ×ª×§×œ×•×ª")

# --- 3. ×”×’×“×¨×ª API ---
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
else:
    st.error("âš ï¸ ××¤×ª×— API ×—×¡×¨.")
    st.stop()

# --- 4. ×¤×•× ×§×¦×™×” ×—×›××” ×œ×‘×—×™×¨×ª ××•×“×œ ×¢×•×‘×“ ---
def get_working_model():
    # ×¨×©×™××ª ×”××•×“×œ×™× ××”×˜×•×‘ ×œ×¤×—×•×ª ×˜×•×‘
    candidates = [
        "gemini-1.5-flash", 
        "gemini-1.5-pro", 
        "gemini-pro", 
        "gemini-1.0-pro"
    ]
    
    # ×‘×“×™×§×” ×× ×›×‘×¨ ××¦×× ×• ××•×“×œ ×¢×•×‘×“ ×•×©××¨× ×• ×‘×–×™×›×¨×•×Ÿ
    if "working_model_name" in st.session_state:
        return genai.GenerativeModel(
            st.session_state.working_model_name,
            generation_config={"temperature": 0.1},
            system_instruction="××ª×” ×× ×œ×™×¡×˜ ×‘×™×˜×•×—."
        )

    # ×¡×¨×™×§×ª ×”××•×“×œ×™×
    for model_name in candidates:
        try:
            test_model = genai.GenerativeModel(model_name)
            # × ×™×¡×™×•×Ÿ "×©×œ×•×" ×§×˜×Ÿ ×›×“×™ ×œ×¨××•×ª ×× ×”××•×“×œ ××’×™×‘
            test_model.generate_content("test") 
            st.session_state.working_model_name = model_name
            st.toast(f"âœ… ×”××¢×¨×›×ª ×”×ª×—×‘×¨×” ×‘×”×¦×œ×—×” ×œ××•×“×œ: {model_name}", icon="ğŸ¤–")
            return genai.GenerativeModel(
                model_name,
                generation_config={"temperature": 0.1},
                system_instruction="××ª×” ×× ×œ×™×¡×˜ ×‘×™×˜×•×—."
            )
        except Exception:
            continue # × ×¡×” ××ª ×”×‘× ×‘×ª×•×¨
            
    st.error("âŒ ×œ× × ××¦× ××•×“×œ ×¤×¢×™×œ ×‘×—×©×‘×•×Ÿ ×–×”. × ×¡×” ×œ×”×—×œ×™×£ API Key.")
    st.stop()

# ××ª×—×•×œ ×”××•×“×œ ×©× ×‘×—×¨
model = get_working_model()

# --- 5. ×¤×•× ×§×¦×™×•×ª ×¢×–×¨ ---
def upload_to_gemini(path):
    status = st.empty()
    status.info("ğŸš€ ××¢×œ×” ×“×•×—...")
    file = genai.upload_file(path, mime_type="application/pdf")
    while file.state.name == "PROCESSING":
        time.sleep(1)
        file = genai.get_file(file.name)
    if file.state.name != "ACTIVE":
        raise Exception("×¢×™×‘×•×“ × ×›×©×œ")
    status.empty()
    return file

# --- 6. ×¦×“ ×™××™×Ÿ ---
base_path = "data/Insurance_Warehouse" 
with st.sidebar:
    st.header("ğŸ—„ï¸ × ×ª×•× ×™×")
    mode = st.radio("×‘×—×¨:", ["GitHub", "×™×“× ×™"])
    selected_file_path = None
    uploaded_user_file = None

    if mode == "GitHub":
        if os.path.exists(base_path):
            companies = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]
            if companies:
                col1, col2 = st.columns(2)
                with col1: company = st.selectbox("×—×‘×¨×”", companies)
                with col2: 
                    yp = os.path.join(base_path, company)
                    years = [d for d in os.listdir(yp) if os.path.isdir(os.path.join(yp, d))] if os.path.exists(yp) else ["2025"]
                    year = st.selectbox("×©× ×”", years)
                quarter = st.selectbox("×¨×‘×¢×•×Ÿ", ["Q1", "Q2", "Q3", "Q4"])
                sp = os.path.join(base_path, company, year, quarter, "Financial_Reports")
                if os.path.exists(sp):
                    files = [f for f in os.listdir(sp) if f.endswith(".pdf")]
                    if files:
                        fname = st.selectbox("×“×•×—", files)
                        selected_file_path = os.path.join(sp, fname)
                    else: st.warning("××™×Ÿ ×§×‘×¦×™×")
                else: st.warning("×ª×™×§×™×™×” ×¨×™×§×”")
            else: st.warning("××™×Ÿ ×—×‘×¨×•×ª")
        else: st.error("××™×Ÿ ××¨×›×™×•×Ÿ")
    else:
        uploaded_user_file = st.file_uploader("×”×¢×œ×” ×§×•×‘×¥", type=['pdf'])

# --- 7. ×œ×•×’×™×§×” ×¨××©×™×ª ---
final_path = selected_file_path
if uploaded_user_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_user_file.getvalue())
        final_path = tmp.name

if final_path:
    if "curr_path" not in st.session_state or st.session_state.curr_path != final_path:
        try:
            st.session_state.gfile = upload_to_gemini(final_path)
            st.session_state.curr_path = final_path
            st.session_state.chat = []
            st.success("××—×•×‘×¨!")
        except Exception as e: st.error(f"×©×’×™××”: {e}")

    if "chat" not in st.session_state: st.session_state.chat = []
    
    for msg in st.session_state.chat:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input("×©××œ ×©××œ×”..."):
        st.chat_message("user").write(prompt)
        st.session_state.chat.append({"role": "user", "content": prompt})
        
        with st.chat_message("assistant"):
            ph = st.empty()
            full_res = ""
            try:
                # ×©×™××•×© ×‘××•×“×œ ×©× ×‘×—×¨ ××•×˜×•××˜×™×ª
                res = model.generate_content([st.session_state.gfile, prompt], stream=True)
                for chunk in res:
                    if chunk.text:
                        full_res += chunk.text
                        ph.markdown(full_res + "â–Œ")
                ph.markdown(full_res)
                st.session_state.chat.append({"role": "assistant", "content": full_res})
            except Exception as e:
                ph.error(f"×©×’×™××”: {e}")
