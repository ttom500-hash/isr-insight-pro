import streamlit as st
import google.generativeai as genai
import tempfile
import os
import time

# --- 1. ×”×’×“×¨×ª ×“×£ ---
st.set_page_config(page_title="Apex Pro", layout="wide")

# --- 2. ×¢×™×¦×•×‘ RTL ---
st.markdown("""
<style>
    .stApp { direction: rtl; }
    h1, h2, h3, p, div { text-align: right; }
    .stTextInput > div > div > input { text-align: right; }
    .stChatMessage { direction: rtl; text-align: right; }
    p { text-align: right; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ¢ Apex Pro - ×× ×œ×™×¡×˜ ×—×›×")

# --- 3. ×—×™×‘×•×¨ ×œ×’×•×’×œ ---
api_key = st.secrets.get("GOOGLE_API_KEY")

if not api_key:
    st.error("âŒ ×—×¡×¨ ××¤×ª×— ×‘-Secrets.")
    st.stop()

# ×—×™×‘×•×¨ ×¨××©×•× ×™
genai.configure(api_key=api_key)

# --- ×× ×’× ×•×Ÿ "×˜×™×™×¡ ××•×˜×•××˜×™" ×œ××¦×™××ª ××•×“×œ ×ª×§×™×Ÿ ---
@st.cache_resource
def find_working_model():
    try:
        # ×‘×§×©×ª ×¨×©×™××ª ×”××•×“×œ×™× ×”×–××™× ×™× ×œ×š
        models = list(genai.list_models())
        
        # ×—×™×¤×•×© ××•×“×œ ×œ×¤×™ ×¡×“×¨ ×¢×“×™×¤×•×ª
        priority_list = [
            "models/gemini-1.5-flash",
            "models/gemini-1.5-flash-latest",
            "models/gemini-1.5-pro",
            "models/gemini-pro"
        ]
        
        # ×‘×“×™×§×”: ×”×× ××—×“ ××”××•×¢×“×¤×™× ×§×™×™× ×‘×¨×©×™××”?
        for priority in priority_list:
            for m in models:
                if priority in m.name and 'generateContent' in m.supported_generation_methods:
                    return m.name # ××¦×× ×•!
        
        # ×× ×œ× ××¦×× ×• ××•×¢×“×£, × ×™×§×— ××ª ×”×¨××©×•×Ÿ ×©×¢×•×‘×“
        for m in models:
            if 'generateContent' in m.supported_generation_methods:
                return m.name
                
        return None
    except Exception as e:
        st.error(f"×©×’×™××” ×‘××™×ª×•×¨ ××•×“×œ×™×: {e}")
        return None

# ×‘×—×™×¨×ª ×”××•×“×œ
model_name = find_working_model()

if model_name:
    st.caption(f"××—×•×‘×¨ ×œ××•×“×œ: {model_name}")
    model = genai.GenerativeModel(model_name)
else:
    st.error("âŒ ×”××¤×ª×— ×ª×§×™×Ÿ, ××š ×œ× × ××¦××• ××•×“×œ×™× ×–××™× ×™× ×‘×—×©×‘×•×Ÿ ×–×”.")
    st.stop()

# --- 4. ×¤×•× ×§×¦×™×™×ª ×”×¢×œ××” ---
def upload_file(path):
    msg = st.toast("××¢×œ×” ×§×•×‘×¥ ×œ×¢× ×Ÿ ×”×××•×‘×˜×—...", icon="â³")
    
    try:
        file = genai.upload_file(path, mime_type="application/pdf")
        
        # ×”××ª× ×” ×œ×¢×™×‘×•×“
        while file.state.name == "PROCESSING":
            time.sleep(1)
            file = genai.get_file(file.name)
            
        if file.state.name != "ACTIVE":
            raise Exception(f"×”×¢×™×‘×•×“ × ×›×©×œ (×¡×˜×˜×•×¡: {file.state.name})")
            
        msg.toast("×”×“×•×— ××•×›×Ÿ ×œ×¢×‘×•×“×”!", icon="âœ…")
        return file
    except Exception as e:
        st.error(f"×ª×§×œ×” ×‘×”×¢×œ××ª ×”×§×•×‘×¥: {e}")
        return None

# --- 5. ×¦×“ ×™××™×Ÿ (×‘×—×™×¨×ª ×§×•×‘×¥) ---
base_path = "data/Insurance_Warehouse"
selected_file = None

with st.sidebar:
    st.header("××§×•×¨ ×”× ×ª×•× ×™×")
    mode = st.radio("×‘×—×¨:", ["××¨×›×™×•×Ÿ (GitHub)", "×”×¢×œ××” ×™×“× ×™×ª"])
    
    if mode == "××¨×›×™×•×Ÿ (GitHub)":
        if os.path.exists(base_path):
            companies = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]
            if companies:
                comp = st.selectbox("×—×‘×¨×”", companies)
                y_path = os.path.join(base_path, comp)
                years = [d for d in os.listdir(y_path) if os.path.isdir(os.path.join(y_path, d))] if os.path.exists(y_path) else ["2025"]
                year = st.selectbox("×©× ×”", years)
                q = st.selectbox("×¨×‘×¢×•×Ÿ", ["Q1", "Q2", "Q3", "Q4"])
                
                final_dir = os.path.join(base_path, comp, year, q, "Financial_Reports")
                if os.path.exists(final_dir):
                    files = [f for f in os.listdir(final_dir) if f.endswith(".pdf")]
                    if files:
                        fname = st.selectbox("×“×•×—", files)
                        selected_file = os.path.join(final_dir, fname)
                    else: st.warning("××™×Ÿ ×§×‘×¦×™×")
                else: st.warning("×ª×™×§×™×™×” ×¨×™×§×”")
        else: st.error("×ª×™×§×™×™×ª data ×œ× × ××¦××”")
    else:
        up = st.file_uploader("×’×¨×•×¨ PDF", type=['pdf'])
        if up:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as t:
                t.write(up.getvalue())
                selected_file = t.name

# --- 6. ×¦'××˜ ---
if selected_file:
    if "curr_file" not in st.session_state or st.session_state.curr_file != selected_file:
        st.session_state.g_file = upload_file(selected_file)
        if st.session_state.g_file:
            st.session_state.curr_file = selected_file
            st.session_state.history = []

    for msg in st.session_state.get("history", []):
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    if prompt := st.chat_input("×©××œ ×©××œ×”..."):
        with st.chat_message("user"):
            st.write(prompt)
        st.session_state.history.append({"role": "user", "content": prompt})

        if "g_file" in st.session_state:
            with st.chat_message("assistant"):
                with st.spinner("××¢×‘×“..."):
                    try:
                        response = model.generate_content([st.session_state.g_file, prompt], stream=True)
                        full_text = ""
                        ph = st.empty()
                        for chunk in response:
                            if chunk.text:
                                full_text += chunk.text
                                ph.markdown(full_text + "â–Œ")
                        ph.markdown(full_text)
                        st.session_state.history.append({"role": "assistant", "content": full_text})
                    except Exception as e:
                        st.error(f"×©×’×™××”: {e}")
